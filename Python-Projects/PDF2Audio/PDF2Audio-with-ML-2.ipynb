{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Python312\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Loss: 0.0129\n",
      "Epoch 2/3, Average Loss: 0.0036\n",
      "Epoch 3/3, Average Loss: 0.0034\n",
      "Audio book created: output.mp3\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import fitz\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pyttsx3\n",
    "import requests\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    pdf_document = fitz.open(pdf_file)\n",
    "    labels_data = {\n",
    "        'id': [], 'text': [], 'chars': [], 'width': [], 'height': [],\n",
    "        'area': [], 'char_size': [], 'pos_x': [], 'pos_y': [], 'aspect': [], 'font_style': []\n",
    "    }\n",
    "\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for b in blocks:\n",
    "            if 'lines' in b:\n",
    "                for l in b[\"lines\"]:\n",
    "                    for s in l[\"spans\"]:\n",
    "                        text_segment = s[\"text\"]\n",
    "                        font_size = s[\"size\"]\n",
    "                        font_style = s[\"font\"]\n",
    "                        bbox = s[\"bbox\"]\n",
    "\n",
    "                        labels_data['id'].append(len(labels_data['id']) + 1)\n",
    "                        labels_data['text'].append(text_segment)\n",
    "                        labels_data['chars'].append(len(text_segment))\n",
    "                        labels_data['width'].append(bbox[2] - bbox[0])\n",
    "                        labels_data['height'].append(bbox[3] - bbox[1])\n",
    "                        labels_data['area'].append((bbox[2] - bbox[0]) * (bbox[3] - bbox[1]))\n",
    "                        labels_data['char_size'].append(font_size)\n",
    "                        labels_data['pos_x'].append(bbox[0])\n",
    "                        labels_data['pos_y'].append(bbox[1])\n",
    "                        labels_data['aspect'].append((bbox[2] - bbox[0]) / (bbox[3] - bbox[1]))\n",
    "                        labels_data['font_style'].append(font_style)\n",
    "\n",
    "    return pd.DataFrame(labels_data)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join(e for e in text if e.isalnum() or e.isspace())\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def train_model(dataframe):\n",
    "    texts = dataframe['text'].apply(preprocess_text).tolist()\n",
    "    labels = dataframe['layout'].tolist()\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(set(labels)))\n",
    "\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = torch.tensor(label_encoder.fit_transform(labels))\n",
    "\n",
    "    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], encoded_labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    epochs = 3\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids, attention_mask, label = batch\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    model.save_pretrained('./model')\n",
    "    tokenizer.save_pretrained('./model')\n",
    "\n",
    "    return model, tokenizer, label_encoder\n",
    "\n",
    "def classify_sections(model, tokenizer, label_encoder, texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        labels = label_encoder.inverse_transform(predictions.numpy())\n",
    "    return labels\n",
    "\n",
    "def filter_text(dataframe, labels_to_keep):\n",
    "    return dataframe[dataframe['layout'].isin(labels_to_keep)]\n",
    "\n",
    "def text_to_speech(text, output_file):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.save_to_file(text, output_file)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def main(pdf_file):\n",
    "    dataframe = extract_text_from_pdf(pdf_file)\n",
    "    \n",
    "    dataframe['layout'] = ['Header' if x > 12 else 'Text' for x in dataframe['char_size']]\n",
    "\n",
    "    model, tokenizer, label_encoder = train_model(dataframe)\n",
    "\n",
    "    texts = dataframe['text'].apply(preprocess_text).tolist()\n",
    "    labels = classify_sections(model, tokenizer, label_encoder, texts)\n",
    "    dataframe['layout'] = labels\n",
    "\n",
    "    important_sections = ['Header', 'Text']\n",
    "    filtered_dataframe = filter_text(dataframe, important_sections)\n",
    "\n",
    "    text_to_speech(' '.join(filtered_dataframe['text']), 'output.mp3')\n",
    "\n",
    "    print(\"Audio book created: output.mp3\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"2303.16727v2.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmB3KBX77LTS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, InputLayer, BatchNormalization, Input\n",
        "from tensorflow.keras.losses import MeanSquaredError, Huber, MeanAbsoluteError, BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Data"
      ],
      "metadata": {
        "id": "yb62wJv07bmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, dataset_info = tfds.load('malaria', with_info=True, as_supervised=True, shuffle_files=True, split=['train'])"
      ],
      "metadata": {
        "id": "ZhnJuOtK7doz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "qlEfQ-Lg7ejf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_info"
      ],
      "metadata": {
        "id": "gS2URLrU7feV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in dataset[0].take(1):\n",
        "  print(data)\n",
        "  break"
      ],
      "metadata": {
        "id": "PB_T_MOu7grP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def splits(dataset, train_ratio, val_ratio, test_ratio):\n",
        "\n",
        "  DATASET_SIZE = len(dataset)\n",
        "\n",
        "  train_dataset = dataset.take(int(train_ratio*DATASET_SIZE))\n",
        "\n",
        "  val_test_dataset = dataset.skip(int(train_ratio*DATASET_SIZE))\n",
        "  val_dataset = val_test_dataset.take(int(val_ratio*DATASET_SIZE))\n",
        "\n",
        "  test_dataset = val_test_dataset.skip(int(val_ratio*DATASET_SIZE))\n",
        "\n",
        "  return train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "UpUDyV4U7io1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_RATIO = 0.8\n",
        "VAL_RATIO = 0.1\n",
        "TEST_RATIO = 0.1\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = splits(dataset[0], TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n",
        "print(list(train_dataset.take(1).as_numpy_iterator()),\n",
        "      list(val_dataset.take(1).as_numpy_iterator()), list(test_dataset.take(1).as_numpy_iterator()))"
      ],
      "metadata": {
        "id": "12woeoRN7joV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Visualization"
      ],
      "metadata": {
        "id": "Vw9IkBGj7n0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (image, label) in enumerate(train_dataset.take(16)):\n",
        "  ax = plt.subplot(4, 4, i + 1)\n",
        "  plt.imshow(image)\n",
        "  plt.title(dataset_info.features['label'].int2str(label))\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "gSYa3x5j7ktw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "QYJgGZjZ7pZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IM_SIZE = 224\n",
        "def resizing_rescaling(image, label):\n",
        "  return tf.image.resize(image, (IM_SIZE, IM_SIZE))/255.0, label"
      ],
      "metadata": {
        "id": "b5Fxyhik7l1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(resizing_rescaling)\n",
        "val_dataset = val_dataset.map(resizing_rescaling)\n",
        "test_dataset = test_dataset.map(resizing_rescaling)\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "_t2N7_887mt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in train_dataset.take(1):\n",
        "  print(image, label)"
      ],
      "metadata": {
        "id": "GOp93gJ_7tPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "OZfIpbfB7uU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Subclassing"
      ],
      "metadata": {
        "id": "YMr6sAXn7xlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(Layer):\n",
        "  def __init__(self):\n",
        "    super(FeatureExtractor, self).__init__()\n",
        "\n",
        "    self.conv_1 = Conv2D(filters=6, kernel_size=3, strides=1, padding='valid', activation='relu')\n",
        "    self.batch_1 = BatchNormalization()\n",
        "    self.pool_1 = MaxPool2D(pool_size=2, strides=2)\n",
        "    self.conv_2 = Conv2D(filters=16, kernel_size=3, strides=1, padding='valid', activation='relu')\n",
        "    self.batch_2 = BatchNormalization()\n",
        "    self.pool_2 = MaxPool2D(pool_size=2, strides=2)\n",
        "\n",
        "  def call(self, x, training):\n",
        "    x = self.conv_1(x)\n",
        "    x = self.batch_1(x)\n",
        "    x = self.pool_1(x)\n",
        "    x = self.conv_2(x)\n",
        "    x = self.batch_2(x)\n",
        "    x = self.pool_2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "feature_sub_classed = FeatureExtractor()"
      ],
      "metadata": {
        "id": "Y9kZc3Rj70t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LenetModel(Model):\n",
        "  def __init__(self):\n",
        "    super(LenetModel, self).__init__()\n",
        "\n",
        "    self.feature_extractor = FeatureExtractor()\n",
        "    self.flatten = Flatten()\n",
        "    self.dense_1 = Dense(100, activation='relu')\n",
        "    self.batch_1 = BatchNormalization()\n",
        "    self.dense_2 = Dense(10, activation='relu')\n",
        "    self.batch_2 = BatchNormalization()\n",
        "    self.dense_3 = Dense(1, activation='sigmoid')\n",
        "\n",
        "  def call(self, x, training):\n",
        "    x = self.feature_extractor(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense_1(x)\n",
        "    x = self.batch_1(x)\n",
        "    x = self.dense_2(x)\n",
        "    x = self.batch_2(x)\n",
        "    x = self.dense_3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "lenet_model_sub = LenetModel()\n",
        "lenet_model_sub(tf.zeros([1,224,224,3]))\n",
        "lenet_model_sub.summary()"
      ],
      "metadata": {
        "id": "Kjv13Mx9BsEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model_sub.compile(optimizer=Adam(learning_rate=0.01),\n",
        "              loss=BinaryCrossentropy(),\n",
        "              metrics='accuracy',\n",
        "              )"
      ],
      "metadata": {
        "id": "BWtGbmWA73ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = lenet_model_sub.fit(train_dataset, validation_data=val_dataset, epochs=20, verbose=1)"
      ],
      "metadata": {
        "id": "ETayo8qW75ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hLtX02YR76-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation and Testing"
      ],
      "metadata": {
        "id": "fZGJXM2s773Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_dataset.batch(1)"
      ],
      "metadata": {
        "id": "ytAK8t5o7_Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model_sub.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "nlYwix9T8AUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model_sub.predict(test_dataset.take(1))[0][0]"
      ],
      "metadata": {
        "id": "CiKaZz_-8BdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parasite_or_not(x):\n",
        "  if (x < 0.5):\n",
        "    return str('P')\n",
        "  else:\n",
        "    return str('U')"
      ],
      "metadata": {
        "id": "x0jw6k4Z8CWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parasite_or_not(lenet_model_sub.predict(test_dataset.take(1))[0][0])"
      ],
      "metadata": {
        "id": "D8I86col8Dtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (image, label) in enumerate(test_dataset.take(9)):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image[0])\n",
        "  plt.title(str(parasite_or_not(label.numpy()[0])) + ':' + str(parasite_or_not(lenet_model_sub.predict(image)[0][0])))\n",
        "\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "lQNP7wcb8E3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model_sub.save('lenet_model_sub.keras')"
      ],
      "metadata": {
        "id": "0lZX8O3R8GGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_loaded_model = tf.keras.models.load_model('lenet_model_sub.keras')\n",
        "lenet_loaded_model.summary()"
      ],
      "metadata": {
        "id": "0e8y9p148HFd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}